# -*- coding: utf-8 -*-
"""Text_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fJzTi7nEtI_BIzlYC8i3WK4gRy6uXT2I
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout

# get data files
!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv
!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv

train_file_path = "train-data.tsv"
test_file_path = "valid-data.tsv"

# Load data
train_df = pd.read_csv(train_file_path, sep="\t")
test_df = pd.read_csv(test_file_path, sep="\t")

train_df.head()

# Load data with column heading
train_df = pd.read_csv(train_file_path, sep="\t", header=None, names=['label', 'message'])
test_df = pd.read_csv(test_file_path, sep="\t", header=None, names=['label', 'message'])

train_df.head()

# Split data into inputs and labels
train_sentences = train_df['message'].tolist()
train_labels_str = train_df['label'].tolist()
test_sentences = test_df['message'].tolist()
test_labels_str = test_df['label'].tolist()

# Convert 'ham' to 0, 'spam' to 1
train_labels = np.array([1 if label == 'spam' else 0 for label in train_labels_str])
test_labels = np.array([1 if label == 'spam' else 0 for label in test_labels_str])

# Preprocess the data using tokenization and padding
vocab_size = 10000
oov_token = "<OOV>"
padding_type = 'post'
trunc_type = 'post'

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)
tokenizer.fit_on_texts(train_sentences)

max_len = max(len(s.split()) for s in train_sentences)

train_sequences = tokenizer.texts_to_sequences(train_sentences)
train_padded = pad_sequences(train_sequences, padding=padding_type, truncating=trunc_type, maxlen=max_len)

test_sequences = tokenizer.texts_to_sequences(test_sentences)
test_padded = pad_sequences(test_sequences, padding=padding_type, truncating=trunc_type, maxlen=max_len)

# Build the model
embedding_dim = 64
dropout_rate = 0.3

model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=max_len),
    Bidirectional(LSTM(64)),
    Dropout(dropout_rate),
    Dense(32, activation='relu'),
    Dropout(dropout_rate),
    Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(train_padded, train_labels, validation_data=(test_padded, test_labels), epochs=5, batch_size=32)

# Define predict_message function
def predict_message(message):
    sequence = tokenizer.texts_to_sequences([message])
    padded = pad_sequences(sequence, maxlen=max_len, padding=padding_type, truncating=trunc_type)
    prediction = model.predict(padded)[0][0]
    label = "spam" if prediction > 0.5 else "ham"
    return [float(prediction), label]

# Test the model using predict_message function
messages = [
    "how are you doing today",
    "sale today! to stop texts call 98912460324",
    "i dont want to go. can we try it a different day? available sat",
    "our new mobile video service is live. just install on your phone to start watching.",
    "you have won Â£1000 cash! call to claim your prize.",
    "i'll bring it tomorrow. don't forget"
]

for msg in messages:
    pred = predict_message(msg)
    print(f"Message: {msg}\nPrediction: {pred}\n")